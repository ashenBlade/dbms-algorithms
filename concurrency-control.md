# Concurrency Control

## Locking CC

### 2PL

### Partition Locking (Coarse-grained)

## Optimistic CC

## Timestamp-based CC

## Multi-version CC (MVCC)

Источники:

- [Multi-Version Concurrency Control (CMU Intro to Database Systems)](https://www.youtube.com/watch?v=niLwbfE3V9Q)
- [An Empirical Evaluation of In-Memory Multi-Version Concurrency Control](https://vldb.org/pvldb/vol10/p781-Wu.pdf)

Идея: у каждого кортежа есть 2 доп. поля:

- Begin ts - время создания кортежа
- End ts - время удаления кортежа

Обработка ведется в зависимости от этих полей.

Принятия решений:

- Concurrency Protocol
- Version storage
- Garbage Collection
- Index Management

Преимущества MVCC:

- Высокий потенциал concurrency, чем single-version system
- Если старые версии не удаляются, то можно использовать time-travel

Общие метаданные:

- Transaction ID - уникальное, монотонное значение для каждой новой транзакции
- У каждого кортежа дополнительно хранится несколько полей:
  - tnx id - tnxid получивший блокировку на котеж (для операций)
  - begin ts (t_xmin) - кто создал
  - end td (t_xmax) - кто удалил
  - pointer (t_ctid) - указатель на следующий кортеж (новее/старее)

Concurrency Control Protocols:

- Timestamp Ordering (MVTO)
  - Самый первый протокол (1979)
  - Использует TNX-ID для расчета serialization order
  - Требует дополнительного поля: read-ts - последняя tnx, читавшая этот кортеж (обновляется перед доступом). Если никто не держит блокировку, но read-ts больше моего - создается новая версия кортежа.
  - Не допускает READ UNCOMMITTED
  - Работа ведется всегда с актуальными версиями кортежа
- Optimistic CC (MVOCC)
  - Второй по порядку (1981)
  - Для добавления поддержки в MVCC добавили несколько доработок в оригинальный OCC - не используется tnx private buffer, т.к. в кортеже и так есть спец. информация, предотвращающая конкурентный доступ/обновление
  - 3 фазы:
    1. Read - читает сами данные. Кортежи проверяем также в зависимости от begin/end ts.
    2. Validation - получаем новый tnx commit id и проверяем, что read-set не был изменен
    3. Write - обновление данных (begin-ts <- tnx commit id, end ts <- INF)
  - Также читаем только актуальные версии
- 2 Phase locking (MV2PL)
  - Использует базовый 2PL протокол для гарантии сериализуемости
  - Перед чтением/обновлением получаем соответствующую блокировку
  - Для disk-based блокировку отдельно от кортежа храним, для memory-based - можно embed
  - tnx-id поле - это write блокировка, а для read - новое поле read-cnt (+ когда читаю, - когда заканчиваю)
  - no-wait стратегия наиболее масштабируемая для предотвращения дедлоков (просто аборт tnx, если не смогли взять блокировку)
- Serialization Certifier
  - Поддерживаем граф сериализации
  - Этот граф отслеживает "опасные структуры (паттерны)", созданные конкурентными tnx
  - Первая версия - SSI, Serializable Snapshot Isolation
    - Отслеживаем anti-dependency edge - создали новую версию кортежа, предыдущая версия которого была прочитана кем-то
    - Только для Snapshot Isolation
  - Вторая версия - SSN, Serial Safety Net
    - Кодируем информацию о зависимостях tnx и валидируем расчетом low watermark (суммаризирует опасные tnx, закоммиченные перед текущий, но должны быть сериализованы после текущей)
    - В сравнении с SSI уменьшает кол-во false abort для read-only/mostly-ro tnx

Version storage:

- Append-only storage
  - Все кортежи хранятся в одном и том же месте
  - Для добавления новой версии, возможно придется создать новую страницу
  - Цепочка версий может храниться в 2 видах:
    - Oldest-to-Newest (O2N) - голова старая, хвост новый
      - Не нужно обновлять индексы на каждый чих (но нужно будет пройтись по цепочке потом - производительность такой системы зависит от механизма очистки старых версий)
      - Так как нужно обойти большую цепочку, то время выполнения tnx увеличивается - увеличивается вероятность конфликтов для больших транзакций
    - Newest-to-Oldest (N2O) - голова новая, хвост старый
      - Нужно обновлять индексы на каждый чих. Решение - уровень маппинга: логич -> физич (очень хорошо работает если много вторичных индексов)
  - С BLOB (non-inline data) проблема в копировании. Решение - хранить в отдельном месте и отслеживать кол-во указателей.
- Time-Travel storage
  - Есть 2 типа таблицы:
    - main - master версии кортежа:
      - текущая в SQL server
      - самая старая в SAP HANA (для snapshot isolation)
    - time-travel - старые версии кортежей
  - Все индексы указывают на мастер версию
  - При обновлении индексы менять не нужно (уже на актуальную версию указывают)
  - Остается проблема BLOB/non-inline (решение то же - отдельная таблица для общих данных)
- Delta storage
  - Есть 2 типа хранилища:
    - main - master версии
    - delta - изменения, которые нужно применить к мастер версии
  - Многие хранят актуальную версию кортежа в main
  - Для обновления выделяем место в delta и записываем туда старые данные измененных атрибутов, а в main записываем уже актуальные (также цепочка версий получается N2O)
  - Много накладных расходов при чтении старых данных

Garbage Collection:

- Tuple-level - проверяем видимость каждого кортежа отдельно
  - Background Vacuuming - фоновый воркер, периодический находящий старые версии
    - Легче всего реализовать
    - Плохо масштабируется
    - Оптимизации:
      - Каждый воркер регистрирует старые версии в lock-free структуре данных, которая потом читается
      - Отслеживаем bitmap грязных блоков, чтобы GC не сканировал те, что не обновлялись (PG VM)
  - Cooperative Cleaning - при обходе цепочки версий находим устаревшие и добавляем в глобальный список, который очищается GC
    - Dusty corner (hekaton) - если какие-то данные не читаем, то устаревшие кортежи не удаляются. Решение - периодически запускаем полноценный GC
- Transaction-level - знаем, что после определенного периода времени данные этой транзакции больше не видны никому, поэтому их можно спокойно удалить
  - Для каждой транзакции нужно отслеживать их read/write set

Index management:

- Logical pointer - фиксированное значение, не меняющееся после любых обновлений кортежа
  - Нужен indirection layer для отображения логического ID на физический - голова цепочки версий
  - Не нужно обновлять все индексы при изменении расположения актуальной версии кортежа
  - Можно использовать:
    - Primary key - в secondary index хранится primary key и далее нужно осмотреть primary index
      - Если ключ secondary index пересекается с primary index, то некоторые атрибуты можно не хранить несколько раз
      - В зависимости от размером этого ключа, очень много места может потребоваться
    - Tuple id - используем какой-то другой ID, назначаемый независимо
      - Можно использовать int64
      - Тогда и lock-free алгоритмы/структуры данных подойдут
- Physical pointer - храним само физическое расположение кортежа
  - Подходит только для append-only хранилища
  - Из вторичного индекса можно получать данные без перехода по всем версиям

## Примеры БД

TODO:

- PostgreSQL
- MySQL
- Oracle
- YDB
- MS SQL Server
- Еще кого-нибудь

## PostgreSQL

На каждое изменение создается новая строка. Хранение кортежей O2N, Append-only

Данные не удаляются в процессе работы, а с помощью VACUUM.
Поэтому нет кластерного индекса, т.к. данные лежат не по порядку (???).

Рабочие поля кортежа:

- `xmin` - tnx создавшая кортеж
- `xmax` - tnx удалившая кортеж
- `cmin` - номер команды внутри tnx, создавшей кортеж
- `cmax` - номер команды внутри tnx, удалившей кортеж

При удалении/обновлении выставляем `xmax`, но если abort, то ставим флаг `

Такая реализация делает ROLLBACK быстрее, т.к. из undo не надо ничего возвращать.

XID - int32, малый достаточно. Поэтому нужен регулярный FREEZE. Для этого специальный XID - 2, Frozen (виден всем).

> Есть дополнительный, Bootstrap = 1

Для оптимизации есть несколько подходов:

- Ленивое назначение XID - только после первой выполненной команды
- Virtual XID - для RO запросов

Для отслеживание состояния транзакций ведется специальный Commit Log (clog).
Хранится на диске и часть в шареной памяти.

Организован в виде файла и на каждую транзакцию - 2 бита: commit/abort.
Файлы хранятся в `pg_xact` директории.

У транзакции есть статусы:

- IN_PROGRESS
- COMMITTED
- ABORTED
- SUB_COMMITTED

Этот файл также очищается VACUUM.

Для определения видимость обычное правило используется: xmin, xmax, xip (список активных транзакций).
Это снапшот. Для READ COMMITTED берется для каждой команды, а остальные - только для первой.

За получение снапшота отвечает функция `GetSnapshotData`. Она является точкой синхронизации и часто ботлнеком для масштабируемости, т.к. нужна LW_EXCLUSIVE блокировка при обновлении транзакции.

### Subtransactions

Нет явных под-`BEGIN`. Вместо них `SAVEPOINT`. Также они создаются неявно внутри обработчиков исключений PLPGSQL.

Назначается XID для подтранзакции (subxid) также как и для основной - vxid для RO, XID после первой команды.
Если у родителя его не было, то он назначается каскадно (вплоть до top-level).

В директории `pg_subtrans` хранится информация о подтранзакциях.

При коммите/аборте top-level tnx - все каскадом для дочерних tnx.

До 64 подтранзакций кешируются в общей памяти, а далее - сброс на диск.

### MultiXAct

Для реализации блокировок кортежей: FOR UPDATE/SHARE.

Когда я хочу заблокировать кортеж:

1. Записываю свой txid в xmax
2. Выставляю infomask - HEAP_XMAX_LOCK_ONLY

Но если у нас уже кто-то заблокировал кортеж, то тут начинает работу MultiXAct.
Вместо реального XID мы создаем новый MultiXAct и записываем его в xmax.

Когда может случиться:

```sql
SELECT * FROM ... FOR SHARE;

-- создается multixact
SELECT * FROM ... FOR SHARE;
```

MultiXAct - это специальная "виртуальная" транзакция, которая хранит множество всех транзакций, взявших блокировку.
Новый MultiXAct создается каждый раз, когда это множество меняется (т.е. отпускают/берут блокировки),
и при этом необходимо все сохранять на диск (директория `pg_multixact`).

> При этом еще не надо забывать, что у нас есть подтранзакции и надо не забывать их обновлять при `ROLLBACK TO`.

### ComboCID

Редко когда одна и та же транзакция вставляет и удаляет одну и ту же строку, поэтому `cmin` и `cmax` объединены в одно поле.
Но если такое случается, то используется специальное значение - `combocid` (combo command id), а затем бэкэнд запоминает `cmin` и `cmax`, которые записал.

Для определения этого используется флаг в инфомаске. Сам combocid назначается как простой счетчик (размер внутреннего массива), а маппинг осуществляется через хэш-таблицу (локальную).

## MySQL

У MySQL архитектура compute-storage separation. Из-за этого CC нужно обрабатывать на обоих уровнях.

Движков хранения много и у каждого свои особенности, но наиболее популярный - InnoDB. Он и поддерживает mvcc.

Старые версии хранятся в undo tablespace в структуре данных rollback segment. Информация в нем используется для выполнения отката в случае rollback/abort.

Также он используется для получения более ранних версий кортежей для поддержки consistent read.

У каждого кортежа имеется 3 системных поля:

1. `DB_TRX_ID` - tnx создавшая кортеж (его версию, INSERT/UPDATE). Удаление - UPDATE, tombstone bit
2. `DB_ROLL_PTR` - roll pointer, указывает на место в undo rollback segment
3. `DB_ROW_ID` - row id, генерируется автоматически

UNDO LOG используется только для кластеризованных индексов есть 2 типов:

1. INSERT UNDO LOG - используется для ROLLBACK транзакций. Отбрасывается как только транзакция закоммитилась.
2. UPDATE UNDO LOG - используется в CONSISTENT READS, чтобы мы могли использовать снапшоты даже после обновления кортежа. Отбрасывается когда (снапшот) больше не нужен.

> Со 2 есть проблема - нужно часто коммитить транзакции, даже если запрашивается только consistent read, иначе rollback segment может вырасти огромным и заполнит все место

Для удаления кортежа мы вначале создаем undo log record, а физическое удаление кортежа происходит только после отбрасывания этого undo log record.

Само удаление называется purge и им занимается отдельный поток (???). Если вставка/удаление происходит часто, небольшими батчами, то таблица может очень быстро расти и транзакции начнут замедляться.
Исправить это можно тротлингом запросов и увеличением ресурсов для purge потока.

Иерархия undo записей:

1. Global Temporary Tablespace
2. Undo tablespace
3. Rollback segment
4. Undo log segment
5. Undo log
6. Undo log record

В каждом undo tablespace может быть максимум 128 rollback segments (настраивается).
Само же количество undo slot зависит от размера страницы (`page size / 16`).

> В процессе работы мы можем достигнуть предела количества конкурентных RW транзакций.
> Происходит когда в выделенном для транзакции rollback segment закончились все слоты.
> Это можно починить переповтором транзакции.

Так как для каждого типа транзакции (INSERT, UPDATE/DELETE) разные типы записей, то и от этого зависит количество одновременных транзакций.

### Блокировки

Для обеспечения согласованности доступа используются блокировки.

Для большей конкурентности используются мультигранулярные:

- Shared/Exclusive
- Intention Shared/Exclusive - table lock с указанием дальнейшего намерения лока отдельного кортежа (т.е. SELECT ... FOR SHARE/UPDATE). Этот тип блокировки накладывается на всю таблицу. Они блокируют только full table request (например LOCK TABLE ... WRITE). Главная цель - показать, что мы собираемся заблокировать кортеж.
- Insert Intention Lock - делает INSERT непосредственно перед вставкой записи, чтобы конкурентные транзакции не блокировали друг-друга, если вставляют РАЗНЫЕ ключи.
- AUTO-INC - table-level lock, когда вставляю записи с AUTO_INCREMENT столбцами, чтобы PRIMARY KEY был последовательным (pg в этом плане проще - может потерять и ему все равно)

При локе записей 3 типа:

- Record Lock - лок на саму запись. В реальности это лок на индексную запись.
- Gap Lock - лок на промежуток между записями (возможно несколькими). Их смысл только в том, чтобы предотвращать вставку другими транзакциями, поэтому нет особой разницы между shared и exclusiveю
    Также существуют псевдо-записи: supremum/minimum. Т.е. до конца и до начала (макс. и мин. ключи).
- Next-key Lock - Record + Gap Lock.

> Со SPATIAL индексами проблема - у них нет последовательности, поэтому там приходится использовать PREDICATE LOCKING

### Транзакционная модель

> По умолчанию, уровень `REPEATABLE READ`

Для поддержания разных уровней транзакций используются разные стратегии взятия блокировок.

- READ UNCOMMITTED - все SELECT неблокирующие и выполняется dirty read
- READ COMMITTED - для каждого consistent read создается новый снапшот. Для (SELECT FOR SHARE/UPDATE)/UPDATE/DELETE лочим только саму запись, но не ее gap, т.е. позволяем создавать фантомов, но для FK и UNIQUE выставляем gap, чтобы найти нарушения
- REPEATABLE READ - для consistent read снапшот берется при первом обращении и до конца транзакции. Для блокирующих операций при чтении блокируется индекс запись и еще gap/next-key lock берется.
  Этот уровень не следует использовать при смешанных non-locking SELECT и locking OP, т.к. SELECT будет использовать старый снапшот (на момент чтения), а locking OP будет изменять уже НОВЫЕ/АКТУАЛЬНЫЕ записи - в таком случае рекомендуется использовать SERIALIZABLE
- SERIALIZABLE - это repeatable read, но все select трансформируются в select ... for update

Consistent read - использование MVCC для чтения кортежей, соответствующих какому-то снапшоту (моменту времени).
При чтении блокировки не берутся, поэтому это чтение неблокирующее, но и поэтому могут возникнуть аномалии, т.к. другие транзакции могут содержимое таблицы свободно изменять.
Используется с READ COMMITTED и REPEATABLE READ.

В MySQL снапшот называется `ReadView` (класс). В нем те же поля, что и в pg:

- m_low_limit_id - верхняя граница, дальшее нее не видим
- m_up_limit_id - нижняя граница, после него все видим
- m_ids - список выполняющихся транзакций

Для их получения необходимо получить блокировку (мьютекс). Причем EXCLUSIVE.

## Oracle


Схема похожа на MySQL

Уровни изоляций такие же как у ISO/SQL, но есть специальные RO версии.
По умолчанию используется READ COMMITTED.

Кроме XID добавляется еще специальный SCN (system change number) - логический внутренний TS.

### Хранилище

Используется UNDO лог.

Разделение на страницы. Каждая страница называется data block (4, 8Кб и т.д.).

Разметка data block:

- Block header - дисковый адрес, tnx информация
- Table directory - (для heap) кортежи каких таблиц тут хранятся, т.е. в одном data block могут хранится разные кортежи
- Row directory - (для heap) тоже самое, что и line pointer array в pg

UNDO записи хранятся в базе данных как обычные данные, а не в каком-то внешнем логе, - undo tablespace.
Для управления этим используется automatic undo management mode - автоматически отслеживает нагрузку и обновляет undo tablespace, чтобы нагрузка не отставала.
При создании транзакции ей назначается свой экстент, в который будет производиться запись undo логов.
Назначение этого экстента производится в циклическом буфере

Для временных таблиц имеется отдельный тип undo записей и свой tablespace.

Для сохранения места вместо того, чтобы хранить XID для каждой записи, весь список XID хранится на странице, а в кортеже только индекс нужного XID.
Также там хранится указатель на последний undo record, созданный для страницы.
Это же используется и для хранения индексов.

### Блокировки

Используется базовая модель: S/X lock.

Общая модель: reader (select), writer (update). Это для записей.

Используемые правила:

1. Блокировка берется только если хотим записать (обновить)
2. Writer не блокирует Reader (undo log)
3. Reader не блокирует Writer (не берет блокировки)

При необходимости выполняется Lock conversion - 1 блокировка низкого уровня повышается до блокировки более высокого.
Это не то же самое, что lock escalation - это когда много (fine-grained) блокировок сразу трансформируются в одну большую (coarse-grained). Этого Oracle не делает, т.к. повышается шанс дедлока.

Сами блокировки длятся столько сколько нужно, например, только на время транзакции.

Блокировки кортежей хранятся не в (отдельном) лок-менеджере, а в блоке данных, который и хранит этот кортеж.
Для добавления используется очередь - когда хочу заблокировать, то кладу лок туда (храню свой XID там).
Мой XID хранится там даже после завершения tnx. Если кто-то другой хочет получить лок, то проверяет активна ли еще блокировка или нет.

Для блокировки таблиц своя иерархия:

1. Row Share - RS (subshare table lock, SS) - кто-то заблокировал кортежи для *возможного* обновления
2. Row Exclusive - RX (subexclusive table lock, SX) - кто-то заблокировал кортежи для обновления (точно знаю, что обновляю), или SELECT ... FOR UPDATE
3. Share Table - S - ???
4. Share Row Exclusive - SRX (share-subexclusive table lock, SSX) - эксклюзивная блокировка, разрешается только (SELECT .. FOR UPDATE)
5. Exclusive - X - самый высокий уровень, запрещающий любые DML

Низко-уровневые примитивы:

- Latch - берется на короткое время для структур данных (т.е. группу объектов).
- Mutex - похож на latch, но берется для одного объекта, а не нескольких
- Internal Lock - высоко-уровневый примитив синхронизации. Нужен для разных задач: dictionary cache, file/log management, tablespace/undo segments

Для latch могут возникать разные феномены:

- latch spinning - в цикле постоянно пытают получить блокировку
- latch sleeping - процесс покидает ЦП до того, как отпустить блокировку

### Транзакции

Каждой транзакции назначается свой Transaction ID. Это не число, а составной тип, указывающий на его место в undo log.

Транзакция начинается, когда первый выполняемый (EXECUTABLE) стейтмент передается, т.е. тот который генерирует вызов к database instance: DML, DDL, SET TRANSACTION.

Когда tnx начинается ей выделяется undo data segment, куда будет писать свои undo данные. Причем XID выделяется ПОСЛЕ этого.

Statement-level atomicity - каждый SQL statement это атомарный unit of work и все либо успешно, либо неуспешно.
При этом, если возникает ошибка, то выполняется statement-level rollback, т.е. откатываются только результаты одного стейтмента, а предыдущие сохраняются. Похоже на постоянный savepoint в pg.

System Change Number (SCN) - внутренний, логический TS, используемый базой данных. Он нужен для упорядочивания событий, произошедших с базой данных. Необходим для ACID.
Зная его, мы можем быстро проводить восстановление - есть watermark до которого знаем, что все применилось.

"На сколько далеко необходимо применять undo?"

Не гарантируется, что будет строго последовательным, т.е. потери нормальны.
Инкрементируется с каждым коммитом. Сохраняется также в REDO записях.

Занимает 8 байт. Но раньше 6: wrap(2) + base(4). Когда после инкрмента base переполняется, то wrap инкрементируется.

Этот SCN хранится в System Global Area. Используется для instance recovery и media recovery (бэкап).

Особые фичи:

- Transaction Guard - специальный API для выполнения транзакций, даже в случае recoverable outage.
С его помощью tnx выполняется не более 1 раза
- Application Continuity
- Autonomous Transactions
- Distributed Transactions
- Flashback query - состояние данных описывается только SCN, поэтому можем выполнять запросы в прошлое. В pg так сделать нельзя, т.к. нужна информация о in-progress транзакциях.

За единицу мульти-версионности отвечает блок. При любом изменении данных в нем создается undo запись, а изменяющая tnx записывается в ITL (interested tnx list) - список tnx, изменяющих этот блок (с другой метаинформацией - статус, момент начала/окончания).

Снимок данных определяется SCN - для получения согласованных данных применяются undo записи, пока SCN блока не станет равным нужному.
Для оптимизации чтобы не ходить в другое место постоянно, на странице сохраняется информация о последней транзакции - commit/abort, т.е. не надо ходить в rollback segment.

COMMIT - просто смена статуса в журнале отката. Для ROLLBACK нужно выполнить откат всех изменений.

## SQL Server

### Хранилище

> Для columnar не используется B+tree, а другие индексы

Ведется Transaction Log - последовательность записей (как в pg). Каждая запись идентифицируется по LSN: LVF (Log Virtual File) ID, Log Block ID, Log Record ID - 0003:000df:0001

Запись лога сохраняет либо:

- Логическую операцию
- Before image - копия данных ПЕРЕД применением операции
- After image - копия данных ПОСЛЕ применения операции

Примеры, что записывается:

- TXN start/end
- DML
- DDL
- File ops (extent/page alloc/dealloc)

Версии строк хранятся:

- В той же БД, если ADR (accelerated database recovery) включена - если места недостаточно, то UPDATE/DELETE провалится, но INSERT будет ок, если места достаточно.
- В `tempdb` - если места недостаточно, то UPDATE будет успешным, но SELECT могут упасть, т.к. нет подходящей версии (не записали просто).

Также дополнительно может быть использовано 14 байт в конце строки для версионной информации. Добавляется когда строка изменяется в первый раз или когда одно из условий выполняется (связаны с тем, что потенциально может быть еще использовано версионирование).

Если ADR включен, то для хранения версий используется PVS - persistent version store, в зависимости от размера до модификации:

- Малый (in-row): Новая строка и старая могут хранится вместе
- Средний (in-row): дельта хранится рядом со строкой
- Большой (off-row): старая строка хранится в отдельной таблице (внутренней)

Для больших данных (до 2Гб, text, blob, image, ...) вся строка разбивается на куски и хранится в виде связного списка. У каждого куска своя версионная информация.

### Блокировки

При доступе к данным запрашивается блокировка. Есть 2 уровня: S/X (как обычно).

> В 2023 добавили фичу - optimized locking. Другая стратегия локов для оптимизации использования памяти.
> Там блокировка идет на транзакцию, а не на весь ресурс.

Длительность блокировки зависит от уровня изоляции, но в конце tnx все отпускаются.

Гранулярность блокировки выбирает сам запрос: ROWID (heap), KEY (Btree), PAGE (8Kb), EXTENT, FILE, etc...

Для более высокой конкурентности есть множество уровней блокировки:

- Shared
- Update - когда подготавливаюсь к update, совместим с shared
- Exclusive
- Intent (IS, IX, SIX)
- Schema
- Bulk Update - несколько разных потоков одновременно вставляют данные. Не конфликтуют только с собой.
- Key-range - защищает диапазон ключей при использовании SERIALIZABLE уровня

> Parallel insert - это фича из SQL Server, но это только через `BULK INSERT` команду.
> У нас похожее, но для INSERT INTO ... SELECT

Есть специальные режимы для range lock (то что в orthogonal key value locking было).

Optimized Locking - вместо того, чтобы на каждый объект класть свой лок мы записываем (???) свой XID в этот ресурс и таким образом блокируем его. Теперь мы ждем окончания самой транзакции и не надо по одной блокировке за раз освобождать.

> Для оптимизации gap блокировки берутся только когда есть конкурентные SERIALIZABLE транзакции.

Если на системе больше 16 vCPU, то включается автоматическое партиционирование блокировок для уменьшения ботлнеков.
При этом партиционируются:

- локи - 1 на множество делится
- память - для каждого CPU свой участок памяти для локов, чтобы уменьшить расходы на перемещение



### Транзакции

Есть 2 режима - явные и неявные tnx (автокоммит).

Поддерживаются и pessimistic и optimistic CC. Выбирать можно на старте транзакции.

> Dirty read они называют uncommitted dependency
> Non-repeatable read - inconsistent analysis

Для согласованности используется любая стратегия изоляции:

- Блокировки
- Row versioning: Read Committed Snapshot (RCSI), Snapshot (Snapshot Isolation)

При row-versioning используется CoW.

Версионирование позволяет реализовать:

- Создание новых кортежей в триггерах (insert/update/delete)
- Поддержка MARS (Multiple Active Result Sets) - если есть уже какие-то измененные в транзакции данные, то коллизии не будет
- `ONLINE` операции с индексов (???)
- Изоляцию, использующую снапшоты (READ COMMITTED, SNAPSHOT ISOLATION)

Используется XSN - Transaction Sequence Number. Инкрементируется каждый раз, когда начинаем транзакцию (но назначается при первой изменяющей команде), изменяющую данные с помощью row versioning.

В самой БД хранится самая последняя строка, а все предыдущие в version store.
Используется linked list для связи с прошлыми версиями.
Если в строке были LOB, то копируется только измененный фрагмент.
БД отслеживает наименьший XSN и удаляет все меньшие, т.к. больше не нужны.

Если row version short-lived, то она может быть даже не сброшена на диск, а закеширована в буфер пуле.

## OrioleDB

Это расширение для postgresql, реализующее table AM.

### Хранилище

Все таблицы - index organized (clustered index). Сам индекс похож на B+tree.

Страницы используют dual pointers для удаления ботлнеков мапинга в буфер пуле - internal узлы указывают либо на in-memory, либо на storage страницы. То есть можно перемещаться с помощью указателей и не ходить в пул буферов.

Для этого используется rightlink (вместо него). Но, что найти sibling, теперь придется идти от родителя. Но, чтобы проблем не было - запрещается вытеснение страницы без rightlink, т.е. во время page split страницы запрещено сбрасывать, а в памяти все с указателями.

В заголовках страницы находится атомарная переменная `state`. Она нужна для реализации локов, а также версионирования (копирую, изменяю локально, проверяю стейт).

Для хранения используется CoW стратегия - на диск вначале попадают целые новые страницы, а во время чекпоинта старые страницы помечаются чистыми.

Поддерживается fuzzy checkpoint (concurrent).

Для MVCC используется UNDO лог - цепочка версий кортежей. Голова - это сами данные на странице, указывает на записи в undo логе. Во время чекпоинта UNDO лог также сохраняется.

Сам UNDO лог хранится в памяти и сбрасывается на диск, только когда места не хватает.

Запись может быть 2 типов:

- row-level - изменения по кортежам
- block-level - изменения всей страницы

Для UNDO лога используется циклический и блочный буфер.

Используется row-level WAL для восстановления и репликации. Восстановление можно параллелизовать - разбиение на воркеры с помощью PK (его хэш).

### Блокировки

### Транзакции

Обновление PK реализовано как delete + insert.

Есть проблема с обновлениями: 1 сессия delete + insert, а 2 - update (предикат на один и тот же ключ), то update будет на новую строку, а не старую.

---

https://www.enterprisedb.com/blog/well-known-databases-use-different-approaches-mvcc

